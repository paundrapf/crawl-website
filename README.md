To start crawling a website and using Web Archive Data Retriever, follow these simple steps:

1.Clone the Repository
Begin by cloning the repository to your local machine:
```
git clone github.com/paundrapf/crawl-website
```

2.Navigate to the Project Directory
Move into the project directory to set up the environment:
```
cd crawl-website
```

3.Install Dependencies
Install the required Python packages using pip:
```
pip install request
```

4.Run the Application
Finally, run the script to start fetching data:
```
py crawl.py
```
